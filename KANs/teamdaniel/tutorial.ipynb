{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from kan import *\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_iris_dataset():\n",
    "    # Load iris dataset\n",
    "    iris = load_iris()\n",
    "    data = iris.data\n",
    "    target = iris.target\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "    target_tensor = torch.tensor(target, dtype=torch.long)\n",
    "\n",
    "    # Split dataset into train and test sets\n",
    "    train_data, test_data, train_target, test_target = train_test_split(data_tensor, target_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create data loaders (optional, if you want to batch and shuffle the data)\n",
    "    train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_target), batch_size=1, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_target), batch_size=1, shuffle=False)\n",
    "\n",
    "    train_inputs = torch.empty(0, 4, device=device)\n",
    "    train_labels = torch.empty(0, dtype=torch.long, device=device)\n",
    "    test_inputs = torch.empty(0, 4, device=device)\n",
    "    test_labels = torch.empty(0, dtype=torch.long, device=device)\n",
    "\n",
    "    # Concatenate all data into a single tensor on the specified device\n",
    "    for data, labels in train_loader:\n",
    "        train_inputs = torch.cat((train_inputs, data.to(device)), dim=0)\n",
    "        train_labels = torch.cat((train_labels, labels.to(device)), dim=0)\n",
    "\n",
    "    for data, labels in test_loader:\n",
    "        test_inputs = torch.cat((test_inputs, data.to(device)), dim=0)\n",
    "        test_labels = torch.cat((test_labels, labels.to(device)), dim=0)\n",
    "\n",
    "    dataset = {}\n",
    "    dataset['train_input'] = train_inputs\n",
    "    dataset['test_input'] = test_inputs\n",
    "    dataset['train_label'] = train_labels\n",
    "    dataset['test_label'] = test_labels\n",
    "\n",
    "    return dataset\n",
    "\n",
    "iris_dataset = load_iris_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([120, 4])\n",
      "Train target shape: torch.Size([120])\n",
      "Test data shape: torch.Size([30, 4])\n",
      "Test target shape: torch.Size([30])\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape: {}\".format(iris_dataset['train_input'].shape))\n",
    "print(\"Train target shape: {}\".format(iris_dataset['train_label'].shape))\n",
    "print(\"Test data shape: {}\".format(iris_dataset['test_input'].shape))\n",
    "print(\"Test target shape: {}\".format(iris_dataset['test_label'].shape))\n",
    "print(\"====================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal_length: 5.400000095367432\n",
      "sepal_width: 3.0\n",
      "petal_length: 4.5\n",
      "petal_width: 1.5\n",
      "Target (numerical): 1\n",
      "Actual Label: versicolor\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def print_example_data_point(dataset):\n",
    "    # Get column names from the dataset\n",
    "    column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
    "\n",
    "    # Get a single data point from the dataset\n",
    "    example_data_point = dataset['train_input'][0]\n",
    "\n",
    "    # Get the corresponding target for the example data point\n",
    "    example_target = int(dataset['train_label'][0])\n",
    "\n",
    "    # Map numerical target to actual string label\n",
    "    target_names = ['setosa', 'versicolor', 'virginica']\n",
    "    actual_label = target_names[example_target]\n",
    "\n",
    "    # Print column names and their corresponding values\n",
    "    for i, column_name in enumerate(column_names):\n",
    "        print(f\"{column_name}: {example_data_point[i]}\")\n",
    "\n",
    "    # Print the target value and the actual string label\n",
    "    print(f\"Target (numerical): {example_target}\")\n",
    "    print(f\"Actual Label: {actual_label}\")\n",
    "\n",
    "print_example_data_point(iris_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KAN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m image_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_img\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mKAN\u001b[49m(width\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m], grid\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m      5\u001b[0m model(iris_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_input\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mplot(beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, in_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSW\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPW\u001b[39m\u001b[38;5;124m'\u001b[39m], out_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVir\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KAN' is not defined"
     ]
    }
   ],
   "source": [
    "image_folder = 'video_img'\n",
    "\n",
    "model = KAN(width=[4, 5, 3], grid=5, k=3, seed=0, device=device)\n",
    "\n",
    "model(iris_dataset['train_input'])\n",
    "model.plot(beta=100, scale=1, in_vars=['SL', 'SW', 'PL', 'PW'], out_vars=['Set', 'Ver', 'Vir'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
